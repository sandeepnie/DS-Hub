{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "E&D Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7QtlO0B3Q7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "# Instantiates the device to be used as GPU/CPU based on availability\n",
        "device_gpu = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pMCCpa04IHy",
        "colab_type": "text"
      },
      "source": [
        "## Data Management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4jGF40w4MUw",
        "colab_type": "text"
      },
      "source": [
        "### Alphabet Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJsZkLMr4DoQ",
        "colab_type": "code",
        "outputId": "45f3e62c-c769-43aa-c925-c18fc77233c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "eng_alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "pad_char = '-PAD-'\n",
        "\n",
        "eng_alpha2index = {pad_char: 0}\n",
        "for index, char in enumerate(eng_alphabets):\n",
        "    eng_alpha2index[char] = index+1\n",
        "print(eng_alpha2index)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P0RHc_H46p0",
        "colab_type": "code",
        "outputId": "5a171783-4d64-412c-bd59-4ed128cf0c77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# Hindi Unicode Hex Range is 2304:2432. Source: https://en.wikipedia.org/wiki/Devanagari_(Unicode_block)\n",
        "hindi_alphabets = [chr(alpha) for alpha in range(2304, 2432)]\n",
        "hindi_alphabet_size = len(hindi_alphabets)\n",
        "\n",
        "hindi_alpha2index = {pad_char: 0}\n",
        "for index, alpha in enumerate(hindi_alphabets):\n",
        "    hindi_alpha2index[alpha] = index+1\n",
        "\n",
        "print(hindi_alpha2index)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-PAD-': 0, 'ऀ': 1, 'ँ': 2, 'ं': 3, 'ः': 4, 'ऄ': 5, 'अ': 6, 'आ': 7, 'इ': 8, 'ई': 9, 'उ': 10, 'ऊ': 11, 'ऋ': 12, 'ऌ': 13, 'ऍ': 14, 'ऎ': 15, 'ए': 16, 'ऐ': 17, 'ऑ': 18, 'ऒ': 19, 'ओ': 20, 'औ': 21, 'क': 22, 'ख': 23, 'ग': 24, 'घ': 25, 'ङ': 26, 'च': 27, 'छ': 28, 'ज': 29, 'झ': 30, 'ञ': 31, 'ट': 32, 'ठ': 33, 'ड': 34, 'ढ': 35, 'ण': 36, 'त': 37, 'थ': 38, 'द': 39, 'ध': 40, 'न': 41, 'ऩ': 42, 'प': 43, 'फ': 44, 'ब': 45, 'भ': 46, 'म': 47, 'य': 48, 'र': 49, 'ऱ': 50, 'ल': 51, 'ळ': 52, 'ऴ': 53, 'व': 54, 'श': 55, 'ष': 56, 'स': 57, 'ह': 58, 'ऺ': 59, 'ऻ': 60, '़': 61, 'ऽ': 62, 'ा': 63, 'ि': 64, 'ी': 65, 'ु': 66, 'ू': 67, 'ृ': 68, 'ॄ': 69, 'ॅ': 70, 'ॆ': 71, 'े': 72, 'ै': 73, 'ॉ': 74, 'ॊ': 75, 'ो': 76, 'ौ': 77, '्': 78, 'ॎ': 79, 'ॏ': 80, 'ॐ': 81, '॑': 82, '॒': 83, '॓': 84, '॔': 85, 'ॕ': 86, 'ॖ': 87, 'ॗ': 88, 'क़': 89, 'ख़': 90, 'ग़': 91, 'ज़': 92, 'ड़': 93, 'ढ़': 94, 'फ़': 95, 'य़': 96, 'ॠ': 97, 'ॡ': 98, 'ॢ': 99, 'ॣ': 100, '।': 101, '॥': 102, '०': 103, '१': 104, '२': 105, '३': 106, '४': 107, '५': 108, '६': 109, '७': 110, '८': 111, '९': 112, '॰': 113, 'ॱ': 114, 'ॲ': 115, 'ॳ': 116, 'ॴ': 117, 'ॵ': 118, 'ॶ': 119, 'ॷ': 120, 'ॸ': 121, 'ॹ': 122, 'ॺ': 123, 'ॻ': 124, 'ॼ': 125, 'ॽ': 126, 'ॾ': 127, 'ॿ': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Um5SDa_Q6Dqp",
        "colab_type": "text"
      },
      "source": [
        "## Helper functions for data pre-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YN8lOVuf5lJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "non_eng_letters_regex = re.compile('[^a-zA-Z ]')\n",
        "\n",
        "# Remove all English non-letters\n",
        "def cleanEnglishVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ').upper()\n",
        "    line = non_eng_letters_regex.sub('', line)\n",
        "    return line.split()\n",
        "\n",
        "# Remove all Hindi non-letters\n",
        "def cleanHindiVocab(line):\n",
        "    line = line.replace('-', ' ').replace(',', ' ')\n",
        "    cleaned_line = ''\n",
        "    for char in line:\n",
        "        if char in hindi_alpha2index or char == ' ':\n",
        "            cleaned_line += char\n",
        "    return cleaned_line.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLSNXv_m70z8",
        "colab_type": "text"
      },
      "source": [
        "##Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUPLGkQ97pjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "class TranslitrationDataLoader(Dataset):\n",
        "    def __init__(self, filename):\n",
        "        self.eng_words, self.hindi_words = self.readXMLDataset(filename,cleanHindiVocab)\n",
        "        self.shuffle_indices = list(range(len(self.eng_words)))\n",
        "        random.shuffle(self.shuffle_indices)\n",
        "        self.shuffle_start_index = 0\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.eng_words)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        return self.eng_words[idx], self.hindi_words[idx]\n",
        "\n",
        "    def get_random_sample(self):\n",
        "        return self.__getitem__(np.random.randint(len(self.eng_words)))\n",
        "\n",
        "    def readXMLDataset(self,filename, lang_vocab_cleaner):\n",
        "        translitrationCorpus = ET.parse(filename).getroot()\n",
        "        lang1_words = []\n",
        "        lang2_words = []\n",
        "\n",
        "        for line in translitrationCorpus:\n",
        "            wordlist1 = cleanEnglishVocab(line[0].text)\n",
        "            wordlist2 = lang_vocab_cleaner(line[1].text)\n",
        "\n",
        "            #skip the noisy data\n",
        "            if len(wordlist1) != len(wordlist2):\n",
        "                print(\"Skipping :\", line[0].text, ' - ', line[1].text)\n",
        "                continue\n",
        "\n",
        "            for word in wordlist1:\n",
        "                lang1_words.append(word)\n",
        "            for word in wordlist2:\n",
        "                lang2_words.append(word)\n",
        "\n",
        "        return lang1_words, lang2_words\n",
        "    \n",
        "    def get_batch_from_array(self, batch_size, array):\n",
        "        end = self.shuffle_start_index + batch_size\n",
        "        batch = []\n",
        "        if end >= len(self.eng_words):\n",
        "            batch = [array[i] for i in self.shuffle_indices[0:end%len(self.eng_words)]]\n",
        "            end = len(self.eng_words)\n",
        "        return batch + [array[i] for i in self.shuffle_indices[self.shuffle_start_index: end]]\n",
        "    \n",
        "    def get_batch(self, batch_size, postprocess = True):\n",
        "        eng_batch = self.get_batch_from_array(batch_size,self.eng_words)\n",
        "        hindi_batch = self.get_batch_from_array(batch_size,self.hindi_words)\n",
        "        self.shuffle_start_index += batch_size +1\n",
        "\n",
        "        #Reshuffle if 1 epoch is complete\n",
        "        if self.shuffle_start_index >= len(self.eng_words):\n",
        "            random.shuffle(self.shuffle_indices)\n",
        "            self.shuffle_start_index = 0\n",
        "\n",
        "        return eng_batch, hindi_batch\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkaCnvvWCohd",
        "colab_type": "code",
        "outputId": "5d2e582d-bad8-4134-cb30-9dc9b5596875",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "source": [
        "train_data = TranslitrationDataLoader('NEWS2012-Training-EnHi-13937.xml')\n",
        "test_data = TranslitrationDataLoader('NEWS2012-Ref-EnHi-1000.xml')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Skipping : BARHARWA JUNCTION  -  बरहरवा\n",
            "Skipping : STATE BNK TR  -  स्टेट बैंक ऑफ त्रावणकोर\n",
            "Skipping : SOUTH ARLINGTON CHURCH OF CHRIST  -  साउथ अर्लिंग्टन\n",
            "Skipping : KING EDWARD VII  -  किंग एडवर्ड\n",
            "Skipping : DIBANG VALLEY  -  दिबंगवैली\n",
            "Skipping : ORDER OF VASA  -  ऑडर ऑफ़ द वासा\n",
            "Skipping : AZAMNAGAR ROAD  -  आज़मनगर\n",
            "Skipping : CAPE TOWN  -  केपटाउन\n",
            "Skipping : NEW ZEALAND  -  न्यूज़ीलैंड\n",
            "Skipping : SEA OF THE HEBRIDES  -  सी ऑफ हरब्रिड्‍स\n",
            "Skipping : RAMCOIND  -  राम्को इंड\n",
            "Skipping : KELVINGROVE ART GALLERY AND MUSEUM  -  केल्व‍िनग्रोव आर्ट एण्ड म्युज़ियम\n",
            "Skipping : AUSTRALIAN NATIONAL UNIVERSITY  -  ऑस्ट्रेलियननेशनल यूनिवर्सिटी\n",
            "Skipping : JAHAN AARA  -  जहाँआरा\n",
            "Skipping : NAVABHARAT FERRO ALLOYS  -  नव भारत फ़ैरो अलॉय\n",
            "Skipping : RAMA LINGESHWARA  -  रामालिंगेश्वर\n",
            "Skipping : FAKHRUN NISA  -  फखरुन्निसा\n",
            "Skipping : REDIFF.COM INDIA LIMITED  -  रेडिफ़ डॉट कॉम इंडिया लिमिटेड\n",
            "Skipping : OMKARNATH THAKUR  -  ओंकार नाथ ठाकुर\n",
            "Skipping : OPENTV  -  ओपन टीवी\n",
            "Skipping : ENVOY COMMUNICATIONS GROUP  -  एन्वॉय कम्युनिकेशंस\n",
            "Skipping : WAR OF THE HOLY LEAGUE  -  वार ऑफ होली लीग\n",
            "Skipping : VAPARAISO CHURCH OF CHRIST  -  व्हापरासिओ\n",
            "Skipping : PARIS CHARLES DE GAULLE  -  पेरिस रॉसे चार्ल्स डे ग्यूले\n",
            "Skipping : PARKWAY APOSTOLIC  -  पार्क वे अपोस्टोलिक\n",
            "Skipping : MAUNA LOA  -  मौनालोआ\n",
            "Skipping : MASS MUTUAL LIFE  -  मास म्युच्युअल लाइफ़ इंश्योरेंस\n",
            "Skipping : STATS CHIPPAC  -  स्टेट्सचिपपैक\n",
            "Skipping : NEWFOUNDLAND  -  न्यू फाउंडलैंड\n",
            "Skipping : LONDONHEATHROW  -  लंदन हीथ्रो\n",
            "Skipping : RETALIX  -  रेटालिक्स लि.\n",
            "Skipping : SRISAILAM  -  श्री शैलम\n",
            "Skipping : KARA-KUM  -  काराकुम\n",
            "Skipping : WIND RIVER  -  विंडरिवर\n",
            "Skipping : NETAJI SUBHASH CHANDRA BOSE  -  नेताजी सुभाषचंद्र बोस\n",
            "Skipping : ROCKBROOK UNITED  -  रॉकब्रुक यूनाइटेड मेथोडिस्ट\n",
            "Skipping : WALTER SCOTT  -  वॉल्टरस्कॉट\n",
            "Skipping : COLOURPLUS FASHIONS  -  कलर प्लस फ़ैशन्स\n",
            "Skipping : BAL KRISHNA  -  बालकृष्णा\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF1TbonpMIQA",
        "colab_type": "text"
      },
      "source": [
        "## Basic Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnLh6XAIGN33",
        "colab_type": "code",
        "outputId": "37cf5f0d-1e98-4f01-b84c-5dbacd469bc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "print(\"Length of training dataset = \\t\", len(train_data))\n",
        "print(\"Length of the test dataset = \\t\",len(test_data))\n",
        "\n",
        "print(\"\\n Sample data from training datset:\")\n",
        "for i in range(10):\n",
        "    eng, hindi = train_data.get_random_sample()\n",
        "    print(eng, ' - ', hindi)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of training dataset = \t 20543\n",
            "Length of the test dataset = \t 1000\n",
            "\n",
            " Sample data from training datset:\n",
            "RASPA  -  रैस्पा\n",
            "DWARKA  -  द्वारका\n",
            "PANTANAL  -  पेंटानल\n",
            "KADUTHURUTHI  -  काडूथुरूट्टी\n",
            "BUNDALBAAZ  -  बंडलबाज़\n",
            "MAZDOOR  -  मज़दूर\n",
            "PILGRIM  -  पिलग्रिम\n",
            "WEST  -  वेस्ट\n",
            "FRANZ  -  फ़्रांज़\n",
            "MALK  -  माल्क\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pbg65iwdD1N",
        "colab_type": "text"
      },
      "source": [
        "## Encoding the Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6B0_v18NP2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word_rep(word, letter2index, device = 'cpu'):\n",
        "    rep = torch.zeros(len(word) +1, 1, len(letter2index)).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        rep[letter_index][0][pos] = 1\n",
        "    pad_pos = letter2index[pad_char]\n",
        "    rep[letter_index +1][0][pad_pos] = 1\n",
        "    return rep\n",
        "\n",
        "def gt_rep(word, letter2index, device='cpu'):\n",
        "    gt_rep = torch.zeros([len(word)+1,1], dtype=torch.long).to(device)\n",
        "    for letter_index, letter in enumerate(word):\n",
        "        pos = letter2index[letter]\n",
        "        gt_rep[letter_index][0] = pos\n",
        "    gt_rep[letter_index+1][0] = letter2index[pad_char]\n",
        "    return gt_rep\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0vXT4x5jOHW",
        "colab_type": "code",
        "outputId": "eb0489fd-3731-45e5-e559-a353ea074b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "#let's see some of the encoding examples\n",
        "eng, hindi = train_data.get_random_sample()\n",
        "eng_rep = word_rep(eng, eng_alpha2index)\n",
        "print(eng, eng_rep)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BATTICE tensor([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "        [[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "          0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ey6hT1Qykntb",
        "colab_type": "code",
        "outputId": "a4645be2-8764-4c30-c6dc-79028c05f6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "hindi_gt = gt_rep(hindi, hindi_alpha2index)\n",
        "print(hindi,hindi_gt)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "बैटिस tensor([[45],\n",
            "        [73],\n",
            "        [32],\n",
            "        [64],\n",
            "        [57],\n",
            "        [ 0]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edriFxEhltg_",
        "colab_type": "text"
      },
      "source": [
        "##Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPY6nI7olwQn",
        "colab_type": "text"
      },
      "source": [
        "### Encoder-Decoder (using GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDvZcADBk9SY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_OUTPUT_CHARS = 30\n",
        "class Transliteration_EncoderDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, output_size, verbose= True):\n",
        "        super(Transliteration_EncoderDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.encoder_rnn_cell = nn.GRU(input_size, hidden_size)\n",
        "        self.decoder_rnn_cell = nn.GRU(output_size, hidden_size)\n",
        "\n",
        "        self.h2o = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.verbose = verbose\n",
        "    \n",
        "    def forward(self, input, max_output_char = MAX_OUTPUT_CHARS, device='cpu', ground_truth =None):\n",
        "\n",
        "        #encoder\n",
        "        out, hidden = self.encoder_rnn_cell(input)\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Encoder input ',input.shape)\n",
        "            print('Encoder output ',out.shape)\n",
        "            print('Encoder Hidden ',hidden.shape)\n",
        "        \n",
        "        #decoder\n",
        "        decoder_state = hidden\n",
        "        decoder_input = torch.zeros(1, 1, self.output_size).to(device)\n",
        "        outputs = []\n",
        "\n",
        "        if self.verbose:\n",
        "            print('Decoder state ',decoder_state.shape)\n",
        "            print('Decoder input ', decoder_input.shape)\n",
        "\n",
        "        for i in range(max_output_char):\n",
        "\n",
        "            out, decoder_state = self.decoder_rnn_cell(decoder_input, decoder_state)\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder intermedicate shape ', out.shape)\n",
        "            \n",
        "            out = self.h2o(decoder_state)\n",
        "            out = self.softmax(out)\n",
        "            outputs.append(out.view(1, -1))\n",
        "\n",
        "            if self.verbose:\n",
        "                print('Decoder output ', out.shape)\n",
        "                self.verbose = False\n",
        "            \n",
        "            max_idx = torch.argmax(out, 2, keepdim= True)\n",
        "            if not ground_truth is None:\n",
        "                max_idx = ground_truth[i].reshape(1,1,1)\n",
        "            one_hot = torch.FloatTensor(out.shape).to(device)\n",
        "            one_hot.zero_()\n",
        "            one_hot.scatter_(2, max_idx, 1)\n",
        "\n",
        "            decoder_input = one_hot.detach()\n",
        "        \n",
        "        return outputs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qNxMUEBHGz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(net, word ,max_output_chars, device = 'cpu'):\n",
        "    net = net.eval().to(device) # We are not training the model\n",
        "    word_ohe = word_rep(word, eng_alpha2index) # Convert input to  #combination of one hot vector representation\n",
        "    output = net(word_ohe, max_output_chars)\n",
        "    \n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyTv-PSas-0x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index), verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqYoUdAAtjbp",
        "colab_type": "code",
        "outputId": "f45999ab-dc4e-4659-eb1a-2471edf3477b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "out = infer(net, 'INDIA', 30)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder input  torch.Size([6, 1, 27])\n",
            "Encoder output  torch.Size([6, 1, 256])\n",
            "Encoder Hidden  torch.Size([1, 1, 256])\n",
            "Decoder state  torch.Size([1, 1, 256])\n",
            "Decoder input  torch.Size([1, 1, 129])\n",
            "Decoder intermedicate shape  torch.Size([1, 1, 256])\n",
            "Decoder output  torch.Size([1, 1, 129])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L559RZpPJ1YJ",
        "colab_type": "text"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwgX6cc1J4EL",
        "colab_type": "text"
      },
      "source": [
        "###Core Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcNpr0watrq7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_batch(net, opt, criterion, batch_size, device = 'cpu', teacher_force = False):\n",
        "\n",
        "    net.train().to(device)\n",
        "    opt.zero_grad()\n",
        "    eng_batch, hindi_batch = train_data.get_batch(batch_size)\n",
        "\n",
        "    total_loss = 0\n",
        "    for i in range(batch_size):\n",
        "\n",
        "        input = word_rep(eng_batch[i], eng_alpha2index, device)\n",
        "        gt = gt_rep(hindi_batch[i], hindi_alpha2index, device)\n",
        "        outputs = net(input, gt.shape[0], device, ground_truth= gt if teacher_force else None)\n",
        "\n",
        "        for index, output in enumerate(outputs):\n",
        "            loss = criterion (output, gt[index]) / batch_size\n",
        "            loss.backward(retain_graph = True)\n",
        "            total_loss += loss\n",
        "\n",
        "    opt.step()\n",
        "    return total_loss/batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7Bj0e1lMWZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_setup(net, lr= 0.01, n_batches = 100, batch_size= 10, momentum=0.9, display_freq =5, device= 'cpu'):\n",
        "\n",
        "    net = net.to(device)\n",
        "    criterion = nn.NLLLoss(ignore_index = -1)\n",
        "    opt = optim.Adam(net.parameters(),lr=lr)\n",
        "    teacher_force_upto = n_batches//3\n",
        "\n",
        "    loss_arr = np.zeros(n_batches+1)\n",
        "\n",
        "    for i in range(n_batches):\n",
        "        loss_arr[i+1] = (loss_arr[i]*i + train_batch(net, opt, criterion, batch_size, device = device, teacher_force = i<teacher_force_upto ))/(i + 1)\n",
        "        \n",
        "        if i%display_freq == display_freq -1:\n",
        "            clear_output(wait=True)\n",
        "\n",
        "            print('Iteration ', i , 'Loss: ',loss_arr[i])\n",
        "            plt.figure()\n",
        "            plt.plot(loss_arr[1:i], '-*')\n",
        "            plt.xlabel('Iteration')\n",
        "            plt.ylabel('Loss')\n",
        "            plt.show()\n",
        "            print('\\n\\n')\n",
        "\n",
        "    torch.save(net, 'Model.pt')\n",
        "    return loss_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZzPPkHyQInf",
        "colab_type": "text"
      },
      "source": [
        "#### Training without Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLlRZdOnQDMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = Transliteration_EncoderDecoder(len(eng_alpha2index), 256, len(hindi_alpha2index))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnc_f-NBQjoY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "f391ac58-c13d-4d3d-d8cd-cbf4cd7df46c"
      },
      "source": [
        "train_setup(net, lr= 0.01, n_batches=1000, batch_size= 64, display_freq = 10, device=device_gpu)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration  999 Loss:  0.10479665547609329\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEGCAYAAABy53LJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZlVxMFhZmYVcXCYmVlF/j8JhkfLY5ZduAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Transliteration_EncoderDecoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type LogSoftmax. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.23462348, 0.27173281, ..., 0.10480613, 0.10479666,\n",
              "       0.10476051])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3c0yIijVaE3L",
        "colab_type": "text"
      },
      "source": [
        "## Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaIbnHWzSmWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(net, word , device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    outputs = infer(net,word, 30, device)\n",
        "    hindi_output = ''\n",
        "\n",
        "    for output in outputs:\n",
        "        val, indices = output.topk(1)\n",
        "        index = indices.tolist()[0][0]\n",
        "        if index ==0:\n",
        "            break\n",
        "        hindi_char = hindi_alphabets[index+1]\n",
        "        hindi_output += hindi_char\n",
        "    print(word + ' - ' + hindi_output)\n",
        "\n",
        "    return hindi_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3nZWd2rbPS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_accuracy(net, device = 'cpu'):\n",
        "    net = net.eval().to(device)\n",
        "    predictions  = []\n",
        "    accuracy = 0\n",
        "\n",
        "    for i in range(len(test_data)):\n",
        "        eng, hindi = test_data[i]\n",
        "        gt = gt_rep(hindi, hindi_alpha2index,device)\n",
        "        outputs = infer(net, eng, gt.shape[0], device)\n",
        "        correct = 0\n",
        "\n",
        "        for index, out in enumerate(outputs):\n",
        "            val, indices = out.topk(1)\n",
        "            hindi_pos = indices.tolist()[0]\n",
        "            \n",
        "            if hindi_pos[0] == gt[index][0]:\n",
        "                correct += 1\n",
        "        \n",
        "        accuracy += correct /gt.shape[0]\n",
        "    accuracy /= len(test_data)\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYAJdNq7dNli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "012ece27-2591-4c85-b5a4-a1dd66517359"
      },
      "source": [
        "accuracy = cal_accuracy(net) * 100\n",
        "print(\"Accuracy without Attention: \", accuracy)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy without Attention:  67.30308053058044\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm6UXoMGdZAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}